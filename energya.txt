### README.md ###
# Energy Price Prediction

## INFORMACION PREVIA:

La separaci√≥n entre **pa√≠s** y **bidding zone** en la industria de la energ√≠a se debe a la forma en que funcionan los mercados el√©ctricos en Europa y en otras regiones del mundo. Aqu√≠ te explico las razones principales:

---

### **1. Los mercados el√©ctricos no siempre siguen las fronteras nacionales**
Los mercados de energ√≠a en Europa est√°n organizados en **bidding zones** (zonas de oferta) que no necesariamente coinciden con los l√≠mites geogr√°ficos de los pa√≠ses. 

- Algunos pa√≠ses tienen **varias bidding zones** debido a limitaciones en su red de transmisi√≥n el√©ctrica.  
  - Ejemplo: **Italia** tiene varias zonas de oferta (`IT-North`, `IT-South`, `IT-Sicily`, etc.).
- Otros pa√≠ses **comparten una misma bidding zone** con pa√≠ses vecinos.  
  - Ejemplo: **Alemania y Luxemburgo** est√°n en la misma zona de oferta `DE-LU`.

---

### **2. ¬øQu√© es una Bidding Zone?**
Una **bidding zone** es un √°rea dentro de un mercado el√©ctrico donde los precios de la electricidad son homog√©neos porque no hay restricciones internas significativas en la red de transmisi√≥n.  

- **Si un pa√≠s tiene suficiente capacidad de transmisi√≥n interna**, todo el pa√≠s puede ser una √∫nica bidding zone (ej. Espa√±a `ES`).  
- **Si un pa√≠s tiene cuellos de botella o congesti√≥n en la red de transmisi√≥n**, se divide en m√∫ltiples zonas de oferta para reflejar las diferencias en precios y oferta/demanda (ej. Italia).  
- **Si dos pa√≠ses tienen redes el√©ctricas bien integradas**, pueden compartir la misma zona de oferta (ej. Alemania y Luxemburgo).

---

### **3. Impacto en la Fijaci√≥n de Precios**
Los precios de la electricidad dentro de una misma **bidding zone** son generalmente los mismos, mientras que diferentes zonas pueden tener precios distintos debido a factores como:

- **Capacidad de transmisi√≥n**: Si una regi√≥n genera m√°s energ√≠a renovable pero no puede enviarla a otra regi√≥n con alta demanda, los precios bajar√°n en la primera y subir√°n en la segunda.
- **Demanda y oferta local**: Algunas zonas tienen m√°s generaci√≥n de energ√≠a e√≥lica, solar o nuclear que otras.
- **Interconexiones con otros mercados**: Una zona con muchas conexiones internacionales puede tener precios m√°s estables.

---

### **Ejemplo Pr√°ctico**
Supongamos que quieres analizar los precios de la electricidad en Alemania (`de`):

- Si consultas por **pa√≠s (`COUNTRY=de`)**, podr√≠as estar incluyendo datos generales que no reflejan la variabilidad regional.
- Si consultas por **bidding zone (`BIDDING_ZONE=DE-LU`)**, estar√°s obteniendo datos m√°s espec√≠ficos del mercado real en el que opera Alemania junto con Luxemburgo.

Lo mismo aplica para otros pa√≠ses con m√∫ltiples bidding zones, como Italia, Suecia y Noruega.

---

### **Conclusi√≥n**
El **pa√≠s (`COUNTRY`)** en la API puede representar una agregaci√≥n de datos de todo el pa√≠s, mientras que la **bidding zone (`BIDDING_ZONE`)** refleja mejor los precios reales dentro del mercado el√©ctrico. **Es importante usar `BIDDING_ZONE` si se quiere hacer predicciones precisas de precios de energ√≠a.**

---



### docker-compose.yml ###
services:
  mongo:
    image: mongo:latest
    container_name: mongo_db
    restart: always
    ports:
      - "27017:27017"
    volumes:
      - ./mongodb_data:/data/db
      - ./mongodb_config:/data/configdb


  scheduler:
    build:
      context: .
      dockerfile: DockerfileScheduler
    container_name: scheduler_service
    depends_on:
      - mongo
    environment:
      - ENV_FILE=.env
    env_file:
      - .env
    shm_size: "2gb"  # üõë Evita errores de memoria compartida con Chrome


  api:
    build:
      context: .
      dockerfile: DockerfileApi
    container_name: api_service
    depends_on:
      - mongo
    ports:
      - "8000:8000"
    environment:
      - ENV_FILE=.env
    env_file:
      - .env


### main.py ###
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import joblib
import numpy as np
import logging
from fastapi.middleware.cors import CORSMiddleware

# Configuraci√≥n de logs
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# Cargar modelo entrenado
MODEL_PATH = "models/energy_price_model.pkl"
try:
    model, scaler = joblib.load(MODEL_PATH)
    logger.info("Modelo cargado exitosamente.")
except Exception as e:
    logger.error(f"Error al cargar el modelo: {e}")
    raise RuntimeError("No se pudo cargar el modelo. Aseg√∫rate de que el archivo existe y es v√°lido.")

# Inicializar FastAPI
app = FastAPI(title="Energy Price Prediction API", description="API para predecir el precio de la energ√≠a basado en datos clim√°ticos.", version="1.0")

# Configurar CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Permitir acceso desde cualquier dominio
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Modelo de datos de entrada
class EnergyPredictionRequest(BaseModel):
    temperature: float
    humidity: float
    precipitation: float
    rain: float
    snowfall: float
    surface_pressure: float
    cloud_cover: float
    wind_speed_10m: float
    wind_speed_100m: float
    wind_direction_10m: float
    wind_direction_100m: float
    days_since_start: int  # Representa la distancia en d√≠as desde el inicio del dataset

@app.post("/predict/", summary="Realizar predicci√≥n de precios de energ√≠a", response_model=dict)
def predict(data: EnergyPredictionRequest):
    """



### requirements.txt ###
(Content omitted: external dependencies)
pandas
numpy
scipy
scikit-learn
joblib



### scheduler.py ###
import sys
import os
import time
import datetime
import subprocess
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.interval import IntervalTrigger

sys.stdout.reconfigure(line_buffering=True)  # üöÄ Forzar salida inmediata de logs


# Configuraci√≥n de tiempos de ejecuci√≥n desde variables de entorno
EXTRACTION_INTERVAL = int(os.getenv("EXTRACTION_INTERVAL", 3600))  # 1 hora por defecto
TRAINING_INTERVAL = int(os.getenv("TRAINING_INTERVAL", 86400))  # 24 horas por defecto

scheduler = BackgroundScheduler()


def run_extraction():
    now = datetime.datetime.now(datetime.timezone.utc).strftime("%Y-%m-%d %H:%M:%S")
    print(f"üöÄ [{now}] Ejecutando extracci√≥n de datos...")
    try:
        subprocess.run(["python", "src/data_ingestion.py"], check=True)
        subprocess.run(["python", "src/data_ingestion_meteo.py"], check=True)
        print(f"‚úÖ [{now}] Extracci√≥n completada con √©xito")
    except subprocess.CalledProcessError as e:
        print(f"‚ùå [{now}] Error en extracci√≥n: {e}")


def run_training():
    now = datetime.datetime.now(datetime.timezone.utc).strftime("%Y-%m-%d %H:%M:%S")
    print(f"üìä [{now}] Ejecutando entrenamiento del modelo...")
    try:
        subprocess.run(["python", "src/train_model_batch.py"], check=True)
        print(f"‚úÖ [{now}] Entrenamiento completado con √©xito")
    except subprocess.CalledProcessError as e:
        print(f"‚ùå [{now}] Error en entrenamiento: {e}")


# Programar las tareas con margen de gracia para evitar saltos
scheduler.add_job(run_extraction, IntervalTrigger(seconds=EXTRACTION_INTERVAL),
                  id="extraction", replace_existing=True, misfire_grace_time=60)
scheduler.add_job(run_training, IntervalTrigger(seconds=TRAINING_INTERVAL),
                  id="training", replace_existing=True, misfire_grace_time=60)

if __name__ == "__main__":
    print("\nüéØ Iniciando Scheduler con APScheduler")
    print("üïí Tareas programadas:")
    print(f"   - Extracci√≥n cada {EXTRACTION_INTERVAL} segundos")
    print(f"   - Entrenamiento cada {TRAINING_INTERVAL} segundos")



### src/api.py ###



### src/data_ingestion.py ###
import os
import time
import logging
from pymongo import MongoClient
from datetime import datetime, timedelta
from dotenv import load_dotenv
from web_scrapper import navigate_and_extract

# Cargar variables desde .env
load_dotenv()

# Configuraci√≥n desde .env
MONGO_URI = os.getenv("MONGO_URI")
MONGO_DB = os.getenv("MONGO_DB")
MONGO_COLLECTION = os.getenv("MONGO_COLLECTION")
COUNTRY = os.getenv("COUNTRY", "de")  # Alemania por defecto
BIDDING_ZONE = os.getenv("BIDDING_ZONE", "DE-LU")  # Alemania-Luxemburgo por defecto

# Configurar logging
log_file = "logs/daily_data_ingestion.log"
os.makedirs(os.path.dirname(log_file), exist_ok=True)
logging.basicConfig(filename=log_file, level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# Conectar a MongoDB
client = MongoClient(MONGO_URI)
db = client[MONGO_DB]
collection = db[MONGO_COLLECTION]

def log_message(message):
    """Registrar mensaje en log y consola"""
    logging.info(message)
    print(message)

# Obtener la √∫ltima fecha registrada en MongoDB para la bidding zone espec√≠fica
latest_entry = collection.find_one({"bidding_zone": BIDDING_ZONE}, sort=[("timestamp", -1)])

if latest_entry:
    START_DATE = latest_entry["timestamp"].strftime("%Y-%m-%d")
else:
    START_DATE = (datetime.today() - timedelta(days=1)).strftime("%Y-%m-%d")  # Si no hay datos, toma ayer

END_DATE = datetime.today().strftime("%Y-%m-%d")

def store_prices_in_mongo(data):
    """Almacena los datos en MongoDB evitando duplicados."""
    if data and "unix_seconds" in data and "price" in data and "unit" in data:
        timestamps = data["unix_seconds"]
        prices = data["price"]
        currency = data["unit"]




### src/data_ingestion_meteo.py ###
import logging
import os
from datetime import datetime, timedelta

from dotenv import load_dotenv
from pymongo import MongoClient

from historical_data_ingestion_meteo import fetch_historical_weather_data, transform_weather_data

# Cargar configuraci√≥n desde .env
load_dotenv()

# Configuraci√≥n de Open-Meteo
METEO_API_URL = os.getenv("METEO_API_URL")
LATITUDE = os.getenv("METEO_LATITUDE")
LONGITUDE = os.getenv("METEO_LONGITUDE")

# Configuraci√≥n de MongoDB
MONGO_URI = os.getenv("MONGO_URI")
MONGO_DB = os.getenv("MONGO_DB")
MONGO_COLLECTION_METEO = os.getenv("MONGO_COLLECTION_METEO")

# Conectar a MongoDB
client = MongoClient(MONGO_URI)
db = client[MONGO_DB]
collection = db[MONGO_COLLECTION_METEO]

# Configurar logging
log_file = "logs/daily_data_meteo.log"
os.makedirs(os.path.dirname(log_file), exist_ok=True)
logging.basicConfig(filename=log_file, level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

def log_message(message):
    """Registrar mensaje en log y consola"""
    logging.info(message)
    print(message)

def fetch_daily_weather_data():
    """Solicita los datos del d√≠a anterior a Open-Meteo."""
    start_date = (datetime.today() - timedelta(days=1)).strftime("%Y-%m-%d")
    return fetch_historical_weather_data(start_date, start_date)

def load_weather_data_filtered(data):
    """Carga datos en MongoDB solo si no existen."""
    inserted_count = 0
    for record in data:
        existing_entry = collection.find_one({"timestamp": record["timestamp"]})
        if not existing_entry:
            collection.insert_one(record)
            inserted_count += 1



### src/historical_data_ingestion.py ###
import os
import time
import logging
from datetime import datetime, timedelta
from dotenv import load_dotenv
from pymongo import MongoClient
from web_scrapper import navigate_and_extract  # Importar el web scraper

# Cargar configuraci√≥n desde .env
load_dotenv()

# Configuraci√≥n de MongoDB
MONGO_URI = os.getenv("MONGO_URI")
MONGO_DB = os.getenv("MONGO_DB")
MONGO_COLLECTION = os.getenv("MONGO_COLLECTION")
COUNTRY = os.getenv("COUNTRY", "de")
BIDDING_ZONE = os.getenv("BIDDING_ZONE", "DE-LU")
HISTORICAL_START_DATE = os.getenv("HISTORICAL_START_DATE", "2016-01-01")
SLEEP_TIME = int(os.getenv("SLEEP_TIME", 5))  # Espera entre requests (en segundos)
DAYS_PER_REQUEST = int(os.getenv("DAYS_PER_REQUEST", 7))  # Intervalo de descarga
MAX_RETRIES = int(os.getenv("MAX_RETRIES", 3))  # M√°ximo de reintentos en caso de error

# Configurar logging
log_file = "logs/historical_data.log"
os.makedirs(os.path.dirname(log_file), exist_ok=True)
logging.basicConfig(filename=log_file, level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# Conectar a MongoDB
client = MongoClient(MONGO_URI)
db = client[MONGO_DB]
collection = db[MONGO_COLLECTION]

def log_message(message):
    """Registrar mensaje en log y consola"""
    logging.info(message)
    print(message)

def store_prices_in_mongo(data):
    """Almacena los datos extra√≠dos en MongoDB, incluyendo los precios."""
    if data and "unix_seconds" in data and "price" in data and "unit" in data:
        timestamps = data["unix_seconds"]
        prices = data["price"]
        currency = data["unit"]  # Guardar la unidad (ej. "EUR / MWh")

        if len(timestamps) != len(prices):
            log_message(f"Error: Desajuste entre timestamps ({len(timestamps)}) y precios ({len(prices)}).")
            return

        processed_data = []
        for ts, price in zip(timestamps, prices):



### src/historical_data_ingestion_meteo.py ###
import os
import time
import logging
import requests
from pymongo import MongoClient
from datetime import datetime, timedelta
from dotenv import load_dotenv

# Cargar configuraci√≥n desde .env
load_dotenv()

# Configuraci√≥n de Open-Meteo
METEO_API_URL = os.getenv("METEO_API_URL")
LATITUDE = os.getenv("METEO_LATITUDE")
LONGITUDE = os.getenv("METEO_LONGITUDE")
HISTORICAL_START_DATE = os.getenv("METEO_HISTORICAL_START_DATE")

# Configuraci√≥n de MongoDB
MONGO_URI = os.getenv("MONGO_URI")
MONGO_DB = os.getenv("MONGO_DB")
MONGO_COLLECTION_METEO = os.getenv("MONGO_COLLECTION_METEO")

# Conectar a MongoDB
client = MongoClient(MONGO_URI)
db = client[MONGO_DB]
collection = db[MONGO_COLLECTION_METEO]

# Configurar logging
log_file = "logs/historical_data_meteo.log"
os.makedirs(os.path.dirname(log_file), exist_ok=True)
logging.basicConfig(filename=log_file, level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

def log_message(message):
    """Registrar mensaje en log y consola"""
    logging.info(message)
    print(message)

def fetch_historical_weather_data(start_date, end_date):
    """Solicita datos meteorol√≥gicos a Open-Meteo."""
    params = {
        "latitude": LATITUDE,
        "longitude": LONGITUDE,
        "start_date": start_date,
        "end_date": end_date,
        "hourly": "temperature_2m,relative_humidity_2m,precipitation,rain,snowfall,surface_pressure,cloud_cover,wind_speed_10m,wind_speed_100m,wind_direction_10m,wind_direction_100m",
    }
    try:
        response = requests.get(METEO_API_URL, params=params)
        response.raise_for_status()
        return response.json()



### src/quality_tester.py ###
import joblib
import numpy as np
import pandas as pd
from pymongo import MongoClient
from sklearn.metrics import mean_absolute_error

# Conectar a MongoDB
MONGO_URI = "mongodb://mongo:27017/"
MONGO_DB = "energy_db"  # Reempl√°zalo con el nombre real de tu BD
MONGO_COLLECTION_ENERGY = "energy_prices"
MONGO_COLLECTION_METEO = "weather_data"

client = MongoClient(MONGO_URI)
db = client[MONGO_DB]
collection_energy = db[MONGO_COLLECTION_ENERGY]
collection_meteo = db[MONGO_COLLECTION_METEO]

# Cargar el modelo entrenado
MODEL_PATH = "models/energy_price_model.pkl"
model, scaler = joblib.load(MODEL_PATH)

# N√∫mero de registros a evaluar
SAMPLE_SIZE = 500

# Obtener datos hist√≥ricos de MongoDB
energy_data = list(collection_energy.find({}, {"_id": 0, "timestamp": 1, "price": 1}).limit(SAMPLE_SIZE))
meteo_data = list(collection_meteo.find({}, {"_id": 0, "timestamp": 1, "temperature": 1, "humidity": 1,
                                              "precipitation": 1, "rain": 1, "snowfall": 1, "surface_pressure": 1,
                                              "cloud_cover": 1, "wind_speed_10m": 1, "wind_speed_100m": 1,
                                              "wind_direction_10m": 1, "wind_direction_100m": 1}).limit(SAMPLE_SIZE))

# Convertir a DataFrame
df_energy = pd.DataFrame(energy_data)
df_meteo = pd.DataFrame(meteo_data)

# Asegurar que los timestamps sean datetime para la fusi√≥n
df_energy["timestamp"] = pd.to_datetime(df_energy["timestamp"])
df_meteo["timestamp"] = pd.to_datetime(df_meteo["timestamp"])

# Fusionar datos de precios y meteorol√≥gicos por timestamp
df_merged = pd.merge(df_energy, df_meteo, on="timestamp", how="inner")

# Asegurar que haya datos despu√©s de la fusi√≥n
if df_merged.empty:
    print("‚ö†Ô∏è No hay datos disponibles despu√©s de la fusi√≥n. Abortando.")
    exit()

# Calcular "days_since_start" usando el mismo m√©todo que en el entrenamiento
df_merged["days_since_start"] = (df_merged["timestamp"] - df_merged["timestamp"].min()).dt.days




### src/train_model_batch.py ###
import os
import joblib
import pandas as pd
import numpy as np
from pymongo import MongoClient
from datetime import datetime
from dotenv import load_dotenv
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler

# Cargar configuraci√≥n desde .env
load_dotenv()

# Configuraci√≥n de MongoDB
MONGO_URI = os.getenv("MONGO_URI")
MONGO_DB = os.getenv("MONGO_DB")
MONGO_COLLECTION_ENERGY = os.getenv("MONGO_COLLECTION")  # Datos de energ√≠a
MONGO_COLLECTION_METEO = os.getenv("MONGO_COLLECTION_METEO")  # Datos meteorol√≥gicos
MODEL_PATH = "models/energy_price_model.pkl"
BATCH_SIZE = 50000  # Tama√±o del lote

# Conectar a MongoDB
client = MongoClient(MONGO_URI)
db = client[MONGO_DB]
collection_energy = db[MONGO_COLLECTION_ENERGY]
collection_meteo = db[MONGO_COLLECTION_METEO]

def fetch_data_in_batches():
    """Generador que obtiene datos de MongoDB en lotes."""
    total_records = collection_energy.count_documents({})
    print(f"üîÑ Total de registros en MongoDB: {total_records}")

    for i in range(0, total_records, BATCH_SIZE):
        print(f"üîÑ Obteniendo lote {i // BATCH_SIZE + 1}...")

        energy_batch = list(collection_energy.find({}, {"_id": 0, "timestamp": 1, "price": 1})
                            .skip(i).limit(BATCH_SIZE))

        meteo_batch = list(collection_meteo.find({}, {"_id": 0, "timestamp": 1, "temperature": 1, "humidity": 1,
                                                      "precipitation": 1, "rain": 1, "snowfall": 1,
                                                      "surface_pressure": 1, "cloud_cover": 1,
                                                      "wind_speed_10m": 1, "wind_speed_100m": 1,
                                                      "wind_direction_10m": 1, "wind_direction_100m": 1})
                           .skip(i).limit(BATCH_SIZE))

        if not energy_batch or not meteo_batch:
            print("‚ö†Ô∏è No se encontraron m√°s datos en este lote.")
            break  # Salir si no hay m√°s datos

        print(f"‚úÖ Procesando lote con {len(energy_batch)} registros de energ√≠a y {len(meteo_batch)} de clima.")



### src/web_scrapper.py ###
import os
import time
import json
import logging
import tempfile
import subprocess

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
from pymongo import MongoClient
from datetime import datetime
from dotenv import load_dotenv
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# Cargar configuraci√≥n desde .env
load_dotenv()

# Configuraci√≥n de MongoDB
MONGO_URI = os.getenv("MONGO_URI")
MONGO_DB = os.getenv("MONGO_DB")
MONGO_COLLECTION = os.getenv("MONGO_COLLECTION")
COUNTRY = os.getenv("COUNTRY", "de")
BIDDING_ZONE = os.getenv("BIDDING_ZONE", "DE-LU")
SWAGGER_URL = os.getenv("SWAGGER_URL", "https://api.energy-charts.info/")

# Configurar logging
log_file = "logs/web_scraper.log"
os.makedirs(os.path.dirname(log_file), exist_ok=True)
logging.basicConfig(filename=log_file, level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# **Conectar a MongoDB** y hacer accesible la colecci√≥n
client = MongoClient(MONGO_URI)
db = client[MONGO_DB]
collection = db[MONGO_COLLECTION]

def get_driver():
    options = Options()
    options.headless = True
    options.add_argument("--headless")  # üöÄ Modo sin interfaz gr√°fica
    options.add_argument("--no-sandbox")  # üõ†Ô∏è Requerido en contenedores Docker
    options.add_argument("--disable-dev-shm-usage")  # Evita problemas de memoria compartida
    options.add_argument("--disable-gpu")  # No necesitamos aceleraci√≥n gr√°fica
    options.add_argument("--window-size=1920x1080")

    # üö® No usar --user-data-dir para evitar problemas de sesi√≥n



.
‚îú‚îÄ‚îÄ bundle.sh
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ DockerfileApi
‚îú‚îÄ‚îÄ DockerfileScheduler
‚îú‚îÄ‚îÄ logs
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ historical_data.log
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ historical_data_meteo.log
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ web_scraper.log
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ model_validation_results.csv
‚îú‚îÄ‚îÄ notebooks
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ scheduler.py
‚îú‚îÄ‚îÄ src
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ api.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ data_ingestion_meteo.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ data_ingestion.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ historical_data_ingestion_meteo.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ historical_data_ingestion.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __pycache__
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ historical_data_ingestion_meteo.cpython-312.pyc
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ web_scrapper.cpython-312.pyc
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ quality_tester.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ train_model_batch.py
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ web_scrapper.py
‚îú‚îÄ‚îÄ structure.txt
‚îî‚îÄ‚îÄ test
    ‚îî‚îÄ‚îÄ prediction1.sh

6 directories, 24 files
